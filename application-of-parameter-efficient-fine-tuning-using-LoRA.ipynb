{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "# Application of Parameter-Efficient Fine-Tuning using LoRA\n",
    "\n",
    "## Objective\n",
    "* Load pre-trained LLM model (HuggingFace's Distilbert SST-2) and evaluate its performance against IMDb reviews sentiment data\n",
    "* Perform Parameter-Efficient Fine Tuning on the pre-trained model to improve its effectiveness on IMDb review sentiment analysis\n",
    "* Perform inference using the fine-tuned model and compare its performance gains against the original pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bac96c4",
   "metadata": {},
   "source": [
    "### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40b1df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, \\\n",
    "Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "from evaluate import load as load_metric\n",
    "from transformers.utils import logging\n",
    "import torch\n",
    "import os\n",
    "from peft import LoraConfig, get_peft_model, PeftModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5542624",
   "metadata": {},
   "source": [
    "### Evaluating environment compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d2489f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Tesla T4\n",
      "Total VRAM: 14.57 GB\n",
      "Workers: 4\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    gpu_idx = 0\n",
    "    total = torch.cuda.get_device_properties(gpu_idx).total_memory / (1024**3)\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(gpu_idx)}\")\n",
    "    print(f\"Total VRAM: {total:.2f} GB\")\n",
    "else:\n",
    "    print(\"No GPU detected.\")\n",
    "\n",
    "print(f'Workers: {min(4, os.cpu_count() // 2)}') # Cap at 4 given 4 workers is sufficient for NLP tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c9dd2",
   "metadata": {},
   "source": [
    "### Loading train/test splits of dataset and shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 25000\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 25000\n",
       " })}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize dataset splits\n",
    "splits = ['train', 'test']\n",
    "\n",
    "# Load train/test splits\n",
    "ds = {split: ds for split, ds in zip(splits, load_dataset('imdb', split=splits))}\n",
    "\n",
    "# Shuffle data (to avoid potential of sequenced label data)\n",
    "for split in splits:\n",
    "    ds[split] = ds[split].shuffle() \n",
    "    \n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f9707",
   "metadata": {},
   "source": [
    "### Pre-Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7377cdd1d242f381766ecd11450082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27622103430a41c5a1164bb028ae0298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Function to tokenize a provided list of natural language data\n",
    "#    Truncating data per model restrictions (Distilbert accepts 512 tokens max)\n",
    "#    Will be using data collator, thus no padding parameter added\n",
    "def preprocess_function(batch):\n",
    "    return tokenizer(batch['text'], truncation=True)\n",
    "\n",
    "# Build dataset of tokenized id's\n",
    "tokenized_ds = {}\n",
    "for split in splits:\n",
    "    tokenized_ds[split] = ds[split].map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        remove_columns=['text']\n",
    "    )\n",
    "    \n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56137a1",
   "metadata": {},
   "source": [
    "### Loading HuggingFace sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \\\n",
    "AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25008190",
   "metadata": {},
   "source": [
    "### Evaluating HuggingFace sentiment model as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "720786b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 02:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41226479411125183, 'eval_accuracy': 0.89076, 'eval_f1': 0.8906695686894387, 'eval_runtime': 144.4961, 'eval_samples_per_second': 173.015, 'eval_steps_per_second': 5.412}\n"
     ]
    }
   ],
   "source": [
    "# Loading accuracy and F1 metrics\n",
    "accuracy = load_metric('accuracy')\n",
    "f1 = load_metric('f1')\n",
    "\n",
    "# Function for inputting predictions and calculation accuracy/f1\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        'accuracy': accuracy.compute(predictions=preds, references=labels)['accuracy'],\n",
    "        'f1': f1.compute(predictions=preds, references=labels, average='weighted')['f1']\n",
    "    }\n",
    "\n",
    "# Define arguments for model evaluation \n",
    "args = TrainingArguments(\n",
    "    output_dir='./imdb_distilbert_sst2_baseline',\n",
    "    per_device_eval_batch_size=32, # based on environment compute (14VRAM can handle 32)\n",
    "    dataloader_num_workers=4, # based on environment compute (32 CPU cores can easily handle 4 workers)\n",
    "    fp16=True, # environment has GPU, thus can use half-precision float for faster compute\n",
    ")\n",
    "\n",
    "# Define Trainer for model evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    eval_dataset=tokenized_ds['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Silence warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Run evaluation\n",
    "baseline_metrics = trainer.evaluate()\n",
    "print(baseline_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210157f7",
   "metadata": {},
   "source": [
    "Model did reasonably well.\n",
    "\n",
    "* **89% Accuracy** => out of all test samples, model got 89% of the labels correctly.\n",
    "\n",
    "* **89% F1** => Model did a good job balancing precision (out of all predicted positive, how many actually came in as positive) and recall (out of all that were actually positive, how many were predicted positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db41558",
   "metadata": {},
   "source": [
    "### Initialize LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8, # Controls how much capacity LoRA has to learn new information - 8 is standard (good balance between # of parameters and meaningfulness)\n",
    "    lora_alpha=16, # Amplifies or dampens how strong the LoRA update is - 16 is standard (ensures updates aren't too weak - underfitting - or too strong - destabilizing / catastrophic forgetting)\n",
    "    target_modules=['q_lin', 'v_lin'], # Distributes attention only to query and value projection layers \n",
    "    lora_dropout=0.05, # Regularization to avoid overfitting - given we only have 25K samples to train, keeping it at 5%\n",
    "    bias='none', # Finetuning of bias terms in PEFT layer - bias updates adds little benefit for large pre-trained models, thus leaving them frozen keeps the model stable and memory-efficient\n",
    "    task_type='SEQ_CLS' # Given this is a sequence classification problem\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06a3149",
   "metadata": {},
   "source": [
    "### Wrapping model with LoRA adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 147,456 || all params: 67,694,596 || trainable%: 0.21782536378531603\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(model, lora_config)\n",
    "\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6b9f6c",
   "metadata": {},
   "source": [
    "### Train the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c87a2474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24531924724578857, 'eval_accuracy': 0.9035, 'eval_f1': 0.9033622970979527, 'eval_runtime': 12.8087, 'eval_samples_per_second': 156.144, 'eval_steps_per_second': 2.498, 'epoch': 1.0}\n",
      "{'eval_loss': 0.23148700594902039, 'eval_accuracy': 0.91, 'eval_f1': 0.9099355724238746, 'eval_runtime': 12.8345, 'eval_samples_per_second': 155.83, 'eval_steps_per_second': 2.493, 'epoch': 2.0}\n",
      "{'eval_loss': 0.22654685378074646, 'eval_accuracy': 0.9145, 'eval_f1': 0.9145189333517494, 'eval_runtime': 12.8719, 'eval_samples_per_second': 155.377, 'eval_steps_per_second': 2.486, 'epoch': 3.0}\n",
      "{'train_runtime': 280.1194, 'train_samples_per_second': 53.549, 'train_steps_per_second': 1.681, 'train_loss': 0.2867354212799396, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=471, training_loss=0.2867354212799396, metrics={'train_runtime': 280.1194, 'train_samples_per_second': 53.549, 'train_steps_per_second': 1.681, 'train_loss': 0.2867354212799396, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./imdb_distilbert_sst2_lora',\n",
    "    learning_rate=2e-4, # Standard given we are only training a tiny fraction of parameters, thus can afford faster learning rate without destabilizing the base model\n",
    "    per_device_train_batch_size=32, # Environment compute should be able to handle it\n",
    "    per_device_eval_batch_size=64, # Environment compute should be able to handle it\n",
    "    num_train_epochs=3, # To have an idea if the model is still learning and requires more epochs\n",
    "    weight_decay=0.01, # Regularization by adding penalty to large weights - 0.01 is standard to avoid overfitting/destabilization \n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True, # environment has GPU, thus can use half-precision float for faster compute\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds['train'].select(range(5000)),\n",
    "    eval_dataset=tokenized_ds['test'].select(range(2000)),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21945349",
   "metadata": {},
   "source": [
    "### Model is still learning after 3 epochs, let's run 2 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4265b8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2531, 'learning_rate': 7.261146496815286e-05, 'epoch': 3.18}\n",
      "{'eval_loss': 0.22198882699012756, 'eval_accuracy': 0.9165, 'eval_f1': 0.9165098013745926, 'eval_runtime': 12.7815, 'eval_samples_per_second': 156.476, 'eval_steps_per_second': 2.504, 'epoch': 4.0}\n",
      "{'eval_loss': 0.22097976505756378, 'eval_accuracy': 0.9185, 'eval_f1': 0.9185141338993617, 'eval_runtime': 12.8654, 'eval_samples_per_second': 155.455, 'eval_steps_per_second': 2.487, 'epoch': 5.0}\n",
      "{'train_runtime': 186.99, 'train_samples_per_second': 133.697, 'train_steps_per_second': 4.198, 'train_loss': 0.0990384751824057, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=785, training_loss=0.0990384751824057, metrics={'train_runtime': 186.99, 'train_samples_per_second': 133.697, 'train_steps_per_second': 4.198, 'train_loss': 0.0990384751824057, 'epoch': 5.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./imdb_distilbert_sst2_lora',\n",
    "    learning_rate=2e-4, \n",
    "    per_device_train_batch_size=32, \n",
    "    per_device_eval_batch_size=64, \n",
    "    num_train_epochs=5, # Adjusting to 5 epochs so we can run 2 more \n",
    "    weight_decay=0.01, \n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds['train'].select(range(5000)),\n",
    "    eval_dataset=tokenized_ds['test'].select(range(2000)),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=True) # Resuming from where we left off (3 epochs in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2f02c",
   "metadata": {},
   "source": [
    "This looks good. Although the model is still learning, it's with diminishing returns. We are at a decent point to stop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d383ce3c",
   "metadata": {},
   "source": [
    "### Saving model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tmp/imdb_distilbert_sst2_lora_tokenizer/tokenizer_config.json',\n",
       " './tmp/imdb_distilbert_sst2_lora_tokenizer/special_tokens_map.json',\n",
       " './tmp/imdb_distilbert_sst2_lora_tokenizer/vocab.txt',\n",
       " './tmp/imdb_distilbert_sst2_lora_tokenizer/added_tokens.json',\n",
       " './tmp/imdb_distilbert_sst2_lora_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.save_pretrained('./tmp/imdb_distilbert_sst2_lora')\n",
    "tokenizer.save_pretrained('./tmp/imdb_distilbert_sst2_lora_tokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5de74f",
   "metadata": {},
   "source": [
    "### Reload pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \\\n",
    "AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a93187d",
   "metadata": {},
   "source": [
    "### Load fine-tuned model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DistilBertForSequenceClassification(\n",
       "      (distilbert): DistilBertModel(\n",
       "        (embeddings): Embeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (transformer): Transformer(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(\n",
       "                  in_features=768, out_features=768, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(\n",
       "                  in_features=768, out_features=768, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pre_classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model = PeftModel.from_pretrained(base_model, './tmp/imdb_distilbert_sst2_lora') # Load base model and trained adapters\n",
    "peft_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3d45c1",
   "metadata": {},
   "source": [
    "### Evaluate fine-tuned model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23352672159671783, 'eval_accuracy': 0.90968, 'eval_f1': 0.9096768344982126, 'eval_runtime': 158.5949, 'eval_samples_per_second': 157.634, 'eval_steps_per_second': 4.931}\n",
      "{'eval_loss': 0.23352672159671783, 'eval_accuracy': 0.90968, 'eval_f1': 0.9096768344982126, 'eval_runtime': 158.5949, 'eval_samples_per_second': 157.634, 'eval_steps_per_second': 4.931}\n"
     ]
    }
   ],
   "source": [
    "# Define arguments for model evaluation \n",
    "args = TrainingArguments(\n",
    "    output_dir='./imdb_distilbert_sst2_lora',\n",
    "    per_device_eval_batch_size=32, # based on environment compute (14VRAM can handle 32)\n",
    "    dataloader_num_workers=4, # based on environment compute (32 CPU cores can easily handle 4 workers)\n",
    "    fp16=True, # environment has GPU, thus can use half-precision float for faster compute\n",
    ")\n",
    "\n",
    "# Define Trainer for model evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    eval_dataset=tokenized_ds['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Silence warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Run evaluation\n",
    "peft_metrics = trainer.evaluate()\n",
    "print(peft_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d170cf",
   "metadata": {},
   "source": [
    "### Compare the two model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f42b5624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline (pre-FT): {'eval_accuracy': 0.89076, 'eval_f1': 0.8906695686894387, 'eval_loss': 0.41226479411125183}\n",
      "PEFT (post-FT):    {'eval_accuracy': 0.90968, 'eval_f1': 0.9096768344982126, 'eval_loss': 0.23352672159671783}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBaseline (pre-FT):\", {k: baseline_metrics[k] for k in [\"eval_accuracy\",\"eval_f1\",\"eval_loss\"]})\n",
    "print(\"PEFT (post-FT):   \", {k: peft_metrics[k] for k in [\"eval_accuracy\",\"eval_f1\",\"eval_loss\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5713f2a4",
   "metadata": {},
   "source": [
    "This was a win! We were able to improve accuracy by almost 2%. Especially given we were already at 89% to begin with where marginal gains having a higher marginal cost, we were still able to reduce errors from 11% to 9%!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hf310)",
   "language": "python",
   "name": "hf310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
